# LlamaIndex 

A production-grade document processing and querying system built with LlamaIndex, featuring advanced multi-modal capabilities (text + images), intelligent semantic chunking, comprehensive cost tracking, and real-time metrics collection. Supports PDF image extraction, OCR processing, and intelligent query execution with GPT-4o.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ .env                          # Environment variables (API keys, configuration)
â”œâ”€â”€ .gitignore                    # Git ignore patterns
â”œâ”€â”€ app.py                        # FastAPI web application
â”œâ”€â”€ config.py                     # Pydantic-based configuration with validation
â”œâ”€â”€ docs_processor.py             # Main document processing and indexing engine
â”œâ”€â”€ health_check.py               # System health diagnostics
â”œâ”€â”€ index_metadata.py             # Index and document metadata models
â”œâ”€â”€ logger_config.py              # Logging setup with rich console output
â”œâ”€â”€ main.py                       # Interactive query CLI
â”œâ”€â”€ monitoring.py                 # Resource monitoring utilities
â”œâ”€â”€ view_chunks.py                # Chunk inspection and export tool
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ reqs.txt                      # Python dependencies
â”‚
â”œâ”€â”€ documents/                    # Input documents directory (place PDFs, DOCX, etc.)
â”‚
â”œâ”€â”€ logs/                         # Logging output
â”‚   â””â”€â”€ metrics/                  # Query metrics JSON files
â”‚       â””â”€â”€ metrics_YYYYMMDD_HHMMSS.json
â”‚
â”œâ”€â”€ storage/                      # Persistent index storage
â”‚   â”œâ”€â”€ docstore.json            # Document store
â”‚   â”œâ”€â”€ graph_store.json         # Graph relationships
â”‚   â”œâ”€â”€ image__vector_store.json # Image embeddings
â”‚   â”œâ”€â”€ index_metadata.json      # Index metadata and versioning
â”‚   â””â”€â”€ index_store.json         # Vector index
â”‚
â”œâ”€â”€ temp_multimodal_images/      # Temporary multi-modal processing
â”œâ”€â”€ temp_pdf_images/              # Extracted PDF images
â”‚
â”œâ”€â”€ templates/                    # Web UI templates
â”‚   â””â”€â”€ index.html               # FastAPI query interface
â”‚
â””â”€â”€ utils/                        # Utility modules
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ cost.py                   # Cost calculation for OpenAI API
    â”œâ”€â”€ custom_prompt.py          # Custom prompt templates
    â”œâ”€â”€ langsmith_tracker.py      # LangSmith integration
    â”œâ”€â”€ metrics.py                # Metrics collection and export
    â”œâ”€â”€ multimodal_processor.py   # Multi-modal content processing
    â”œâ”€â”€ pdf_image_extractor.py    # PDF image extraction
    â””â”€â”€ semantic_chunk.py         # Safe semantic chunking implementation
```

---

## ğŸš€ Setup

### Prerequisites
- Python 3.8+
- Docker (for Milvus vector database)
- OpenAI API key
- (Optional) Tesseract OCR for enhanced document detection

### 1. Create Required Directories
```sh
mkdir documents logs storage temp_multimodal_images temp_pdf_images
```

### 2. Install Dependencies
```sh
pip install -r reqs.txt
```

### 3. Configure Environment
Create a `.env` file with your configuration:
```env
# Required
OPENAI_API_KEY=your-api-key-here

# Chunking Strategy Configuration
CHUNKING_STRATEGY=semantic  # Options: 'sentence' or 'semantic'
SEMANTIC_BUFFER_SIZE=1
SEMANTIC_BREAKPOINT_THRESHOLD=75  # 50-99, higher = larger chunks

# Semantic Chunking Safety
MAX_CHUNK_CHARS=2048
MIN_CHUNK_CHARS=200
SEMANTIC_EMBEDDING_BATCH_SIZE=100

# Multi-Modal Processing (GPT-4 Vision)
ENABLE_MULTIMODAL=true
MULTIMODAL_MODEL=gpt-4o
MULTIMODAL_MAX_TOKENS=1024

# PDF Image Extraction
EXTRACT_PDF_IMAGES=true
MIN_IMAGE_SIZE=10000  # Skip small icons/logos

# Optional: LangSmith Tracking
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your-langsmith-key
LANGSMITH_PROJECT=llamaindex

# Optional: Tesseract OCR (if not in PATH)
TESSERACT_CMD=/usr/local/bin/tesseract
```

### 4. Start Milvus Vector Database
```sh
docker-compose up -d
```

Or use standalone Milvus: [Milvus Installation Docs](https://milvus.io/docs/install_standalone-docker.md)

### 5. Add Documents
Place your PDF, DOCX, TXT, MD, PPTX files in the `documents/` directory.

---

## ğŸ“– Usage

### 1. Health Check
Verify all system components are working:
```sh
python health_check.py
```

**Checks:**
- âœ… OpenAI API connectivity
- âœ… Milvus server status
- âœ… Documents directory
- âœ… Index storage
- âœ… OCR availability (if configured)

### 2. Process Documents
Index your documents (first-time or after updates):
```sh
python docs_processor.py
```

**Features:**
- Automatic PDF image extraction
- Smart chunking (sentence or semantic)
- Memory-efficient batch processing
- Streaming mode for large document sets
- Progress bars and detailed statistics

**Example Output:**
```
ğŸ§  Starting semantic chunking for 396 documents
Config: buffer_size=1, threshold=75%, max_chars=2048

Processing documents with semantic chunking... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:42

âœ¨ Semantic Chunking Results
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                          â”‚    Value â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Documents Processed             â”‚      396 â”‚
â”‚ Total Chunks Created            â”‚      680 â”‚
â”‚ Avg Chunks per Document         â”‚      1.7 â”‚
â”‚ Max Chunk Size (Enforced)       â”‚    2,048 â”‚
â”‚ Chunks Requiring Split          â”‚ 0 (0.0%) â”‚
â”‚ Total Processing Time           â”‚    42.5s â”‚
â”‚ Processing Speed                â”‚     9.3/sâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ“ All chunks within size limits!
```

### 3. Query Documents
Run interactive queries:
```sh
python main.py
```

**Features:**
- Multi-query support (enter multiple questions)
- Real-time cost tracking
- Markdown-formatted responses with citations
- Source attribution with page numbers
- Session metrics export


### 4. View Chunks
Inspect indexed document chunks:
```sh
python view_chunks.py
```

**Features:**
- Interactive menu system
- Chunk statistics and analysis
- Sample chunk viewing
- Search and filter options
- Export to text file
- Alternative retrieval via query

### 5. Web Interface (Optional)
Start the web server:
```sh
uvicorn app:app --reload --port 3000
```

Access at: `http://localhost:3000`
